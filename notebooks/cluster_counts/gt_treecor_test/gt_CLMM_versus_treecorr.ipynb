{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10a9ad67-1bc5-4d5d-995d-b8fed6e8d9cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Compare TreeCorr to CLMM for stacked reduced tangential shear measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aae087b-4b7c-4c9b-aa64-8099ca1265bd",
   "metadata": {},
   "source": [
    "<!-- The halo mass function is given by\n",
    "$$\n",
    "\\frac{dn}{dM} = f(\\sigma) \\frac{\\bar{\\rho}_m}{M}\\frac{d ln\\sigma^{-1}}{dM}\n",
    "$$\n",
    "where $\\sigma$ is the variance, $\\bar{\\rho}_m$ is the mean density of the universe, $M$ is the halo mass and $f$ is the multiplicity function. In this notebook we use the Tinker multiplicity function \n",
    "$$\n",
    "f(\\sigma) = A \\left[ \\left(\\frac{\\sigma}{b}\\right)^{-a} +1\\right] e^{-\\frac{c}{\\sigma^2}}\n",
    ".$$\n",
    "In the above, $A$ is the normalization factor and $a,b$ and $c$ are parameters to be set by the model.  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97719af-09d7-40f2-8a7d-0d2790b42764",
   "metadata": {},
   "source": [
    "This notebook compares in a very ideal setup the computation of the stacked reduced shear profile either using CLMM or using TreeCorr to cross-correlate cluster positions with background source shears. The mock data is generated using CLMM.\n",
    "\n",
    "This provides a quick demo of what issue TXPpipe issue #409 aims at doing in spirit..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b56798-1583-4ef3-a491-cfe0ce1ef74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pyccl as ccl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import clmm\n",
    "from clmm import GalaxyCluster, ClusterEnsemble, GCData\n",
    "from clmm import Cosmology\n",
    "from clmm.support import mock_data as mock\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513df539-fe8c-4a3e-8659-599db2a0c73d",
   "metadata": {},
   "source": [
    "For reproducibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e4438c-aa82-48e5-b23d-6a211136b64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8270d7-a8b5-4def-a4d7-ff6a6e58acbb",
   "metadata": {},
   "source": [
    "## Draw pairs of mass and redshift according to a mass function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8af669-b22a-43ca-a1b3-9bf85bae65c9",
   "metadata": {},
   "source": [
    "### Mass function - CCL implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aea0ec5-56b6-4a2e-bf09-3889357c0552",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmo = ccl.Cosmology(\n",
    "    Omega_c=0.265,\n",
    "    Omega_b=0.0448,\n",
    "    h=0.71,\n",
    "    sigma8=0.8,\n",
    "    n_s=0.96,\n",
    "    Neff=3.04,\n",
    "    m_nu=1.0e-05,\n",
    "    mass_split=\"single\",\n",
    ")\n",
    "hmd_200c = ccl.halos.MassDef(200, \"critical\")\n",
    "\n",
    "# For a different multiplicty function, the user must change this function below\n",
    "def tinker08_ccl(logm, z):\n",
    "    mass = 10 ** (logm)\n",
    "    hmf_200c = ccl.halos.MassFuncTinker08(mass_def=hmd_200c)\n",
    "    nm = hmf_200c(cosmo, mass, 1.0 / (1 + z))\n",
    "    return nm  # dn/dlog10M\n",
    "\n",
    "\n",
    "# Computing the volume element\n",
    "def dV_over_dOmega_dz(z):\n",
    "    a = 1.0 / (1.0 + z)\n",
    "    da = ccl.background.angular_diameter_distance(cosmo, a)\n",
    "    E = ccl.background.h_over_h0(cosmo, a)\n",
    "    return ((1.0 + z) ** 2) * (da**2) * ccl.physical_constants.CLIGHT_HMPC / cosmo[\"h\"] / E\n",
    "\n",
    "\n",
    "def pdf_tinker08_ccl(logm, z):\n",
    "    return tinker08_ccl(logm, z) * dV_over_dOmega_dz(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e14265-ee36-4669-9275-5758348acc4e",
   "metadata": {},
   "source": [
    "### Acceptance-rejection method to sample (M,z) from the mass function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec03552-6957-4aac-adfc-c4fc2744dd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bivariate_draw(\n",
    "    pdf, N=1000, logm_min=14.0, logm_max=15.0, zmin=0.01, zmax=1, Ngrid_m=30, Ngrid_z=30\n",
    "):\n",
    "    \"\"\"\n",
    "    Uses the rejection method for generating random numbers derived from an arbitrary\n",
    "    probability distribution.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pdf : func\n",
    "      2d distribution function to sample\n",
    "    N : int\n",
    "      number of points to generate\n",
    "    log_min,logm_max : float\n",
    "      log10 mass range\n",
    "    zmin,zmax : float\n",
    "      redshift range\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    ran_logm : list\n",
    "        accepted logm values\n",
    "    ran_z : list\n",
    "        accepted redshift values\n",
    "    acceptance : float\n",
    "        acceptance ratio of the method\n",
    "    \"\"\"\n",
    "\n",
    "    # maximum value of the pdf over the mass and redshift space.\n",
    "    # the pdf is not monotonous in mass and redshift, so we need\n",
    "    # to find the maximum numerically. Here we scan the space\n",
    "    # with a regular grid and use the maximum value.\n",
    "    # Accuracy of the results depends on Ngrid_m and Ngrid_z\n",
    "    # This should probably be improved\n",
    "\n",
    "    logM_arr = np.linspace(logm_min, logm_max, Ngrid_m)\n",
    "    z_arr = np.logspace(np.log10(zmin), np.log10(zmax), Ngrid_z)\n",
    "    p = []\n",
    "    for logM in logM_arr:\n",
    "        for z in z_arr:\n",
    "            p.append(pdf(logM, z))\n",
    "    pmax = np.max(p)\n",
    "    pmin = np.min(p)\n",
    "    # Counters\n",
    "    naccept = 0\n",
    "    ntrial = 0\n",
    "\n",
    "    # Keeps drawing until N points are accepted\n",
    "    ran_logm = []  # output list of random numbers\n",
    "    ran_z = []  # output list of random numbers\n",
    "    while naccept < N:\n",
    "        # draw (logm,z) from uniform distribution\n",
    "        # draw p from uniform distribution\n",
    "        logm = np.random.uniform(logm_min, logm_max)  # x'\n",
    "        z = np.random.uniform(zmin, zmax)  # x'\n",
    "        p = np.random.uniform(0.0, pmax)  # y'\n",
    "\n",
    "        if p < pdf(logm, z):\n",
    "            # keep the point\n",
    "            #            print(logm, z, p, pdf(logm, z))\n",
    "            ran_logm.append(logm)\n",
    "            ran_z.append(z)\n",
    "            naccept = naccept + 1\n",
    "        ntrial = ntrial + 1\n",
    "\n",
    "    ran_logm = np.asarray(ran_logm)\n",
    "    ran_z = np.asarray(ran_z)\n",
    "\n",
    "    acceptance = float(N / ntrial)\n",
    "    print(f\"acceptance = {acceptance}\")\n",
    "    return ran_logm, ran_z, acceptance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafac5cf-3ef1-4189-b88e-326b4df28829",
   "metadata": {},
   "source": [
    "### Draw N=30 (M,z) pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bd6be3-60b8-47a0-b86b-1659081d7c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the numbers of pairs to draw and the mass and redshift ranges\n",
    "N = 30\n",
    "logm_min = 14.5\n",
    "logm_max = 14.8\n",
    "zmin = 0.2\n",
    "zmax = 0.3\n",
    "\n",
    "pdf = pdf_tinker08_ccl\n",
    "\n",
    "# Normalisation factor for the pdf to be used later\n",
    "norm = (\n",
    "    1.0\n",
    "    / scipy.integrate.dblquad(\n",
    "        pdf, zmin, zmax, lambda x: logm_min, lambda x: logm_max, epsrel=1.0e-4\n",
    "    )[0]\n",
    ")\n",
    "\n",
    "# Random draw\n",
    "ran_logm, ran_z, acceptance = bivariate_draw(\n",
    "    pdf, N=N, logm_min=logm_min, logm_max=logm_max, zmin=zmin, zmax=zmax\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1988a5a5-8a75-4a7b-b8f4-84c50cd45b1f",
   "metadata": {},
   "source": [
    "## Generate a cluster catalog and associated source catalogs\n",
    "- First, set the cluster masses and redshifts given the generated mock data.\n",
    "- Then, instantiate a CCL concentration object to compute the concentration for each cluster from a mass-concentration realtion (Duffy et al. 2008). The actual concentration for each cluster is drawn from a lognormal distribution around the mean value\n",
    "- Last, we randomly generate the cluster center coordinates over the full sky (from 0 to 360 deg for ra and from -90 to 90 deg to dec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66911b7b-b7cf-49a3-97da-0f93895cfafe",
   "metadata": {},
   "source": [
    "### Cluster ensemble masses, redshifts and positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d49918-69ea-43cb-91f4-426373247407",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_m = 10 ** ran_logm\n",
    "cluster_z = ran_z\n",
    "\n",
    "# Concentration CCL object to compute the theoretical concentration\n",
    "conc_obj = ccl.halos.ConcentrationDuffy08(mass_def=hmd_200c)\n",
    "conc_list = []\n",
    "for number in range(0, len(cluster_m)):\n",
    "    a = 1.0 / (1.0 + (cluster_z[number]))\n",
    "    # mean value of the concentration for that cluster\n",
    "    lnc_mean = np.log(conc_obj(cosmo, M=(cluster_m[number]), a=a))\n",
    "    # random draw of actual concentration from normal distribution around lnc_mean, with a 0.14 scatter\n",
    "    lnc = np.random.normal(lnc_mean, 0.14)\n",
    "    conc_list.append(np.exp(lnc))\n",
    "\n",
    "conc_list = np.array(conc_list)\n",
    "\n",
    "# randomly draw cluster positions over the full sky\n",
    "ra = np.random.random(N) * 360  # from 0 to 360 deg\n",
    "sindec = np.random.random(N) * 2 - 1\n",
    "dec = np.arcsin(sindec) * 180 / np.pi  # from -90 to 90 deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3c55f5-8541-45a1-a7bf-6269239b1cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cluster_m)\n",
    "N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7196b0-697c-4547-8305-7dbad76a3537",
   "metadata": {},
   "source": [
    "### Background galaxy catalog generation\n",
    "\n",
    "For each cluster of the ensemble, we use `mock_data` to generate a background galaxy catalog and store the results in a `GalaxyCluster` object. Note that:\n",
    "- The cluster density profiles follow the NFW parametrisation\n",
    "- The source redshifts follow the Chang et al. distribution and have associated pdfs\n",
    "- The shapes include shape noise and shape measurement errors\n",
    "- Background galaxy catalogs are independent, even if the clusters are close (i.e., no common galaxy between two catalogs).\n",
    "- For each cluster we then compute\n",
    "    - the tangential and cross $\\Delta\\Sigma$ for each background galaxy\n",
    "    - the weights `w_ls` to be used to compute the corresponding radial profiles (see `demo_compute_deltasigma_weights.ipynb` notebook for details)\n",
    "\n",
    "The cluster objects are then stored in `gclist`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bc0935-8663-413a-90a6-4b888d2d32ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\n",
    "    \"ignore\"\n",
    ")  # just to prevent warning print out when looping over the cluster ensemble below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76577e8d-4e94-48bd-afb3-483ac0d252be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import Table, vstack\n",
    "gclist = []\n",
    "tables = []\n",
    "# number of galaxies in each cluster field (alternatively, can use the galaxy density instead)\n",
    "#n_gals = 10000\n",
    "ngal_density = 10\n",
    "cosmo_clmm = Cosmology(H0=71.0, Omega_dm0=0.265 - 0.0448, Omega_b0=0.0448, Omega_k0=0.0)\n",
    "cosmo_clmm.set_be_cosmo(cosmo)\n",
    "gal_args = dict(\n",
    "    cosmo=cosmo_clmm,\n",
    "    zsrc=\"chang13\",\n",
    "    delta_so=200,\n",
    "    massdef=\"critical\",\n",
    "    halo_profile_model=\"nfw\",\n",
    "    zsrc_max=2.0,\n",
    "    field_size=30.0,\n",
    "    shapenoise=0.04,\n",
    "    photoz_sigma_unscaled=0.02,\n",
    "#    ngals=n_gals,\n",
    "    ngal_density=ngal_density,\n",
    "    mean_e_err=0.1,\n",
    ")\n",
    "\n",
    "for i in range(N):\n",
    "    # generate background galaxy catalog for cluster i\n",
    "    cl = clmm.GalaxyCluster(\n",
    "        f\"mock_cluster_{i:04}\",\n",
    "        ra[i],\n",
    "        dec[i],\n",
    "        cluster_z[i],\n",
    "        galcat=mock.generate_galaxy_catalog(\n",
    "            cluster_m[i],\n",
    "            cluster_z[i],\n",
    "            conc_list[i],\n",
    "            cluster_ra=ra[i],\n",
    "            cluster_dec=dec[i],\n",
    "            zsrc_min=0.35,  # cluster zmax = 0.3 in this example\n",
    "            **gal_args,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # compute DeltaSigma for each background galaxy\n",
    "    cl.compute_tangential_and_cross_components(\n",
    "        shape_component1=\"e1\",\n",
    "        shape_component2=\"e2\",\n",
    "        tan_component=\"g_t\",\n",
    "        cross_component=\"g_x\",\n",
    "        cosmo=cosmo_clmm,\n",
    "        is_deltasigma=False,\n",
    "        use_pdz=True,\n",
    "    )\n",
    "\n",
    "    # compute the weights to be used to bluid the DeltaSigma radial profiles\n",
    "    cl.compute_galaxy_weights(\n",
    "        use_pdz=True,\n",
    "        use_shape_noise=True,\n",
    "        shape_component1=\"e1\",\n",
    "        shape_component2=\"e2\",\n",
    "        use_shape_error=True,\n",
    "        shape_component1_err=\"e_err\",\n",
    "        shape_component2_err=\"e_err\",\n",
    "        weight_name=\"w_ls\",\n",
    "        cosmo=cosmo_clmm,\n",
    "        is_deltasigma=False,\n",
    "        add=True,\n",
    "    )\n",
    "\n",
    "    # append the cluster in the list\n",
    "    gclist.append(cl)\n",
    "    tables.append(cl.galcat)\n",
    "    \n",
    "galcat_tot = vstack(tables)                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf115b3e-d68b-4ea1-bf8c-5372cba5c88f",
   "metadata": {},
   "source": [
    "## Create ClusterEnsemble object and estimation of individual excess surface density profiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e96711c-2628-4052-aa77-83c008c9ec8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bins = np.logspace(np.log10(0.3), np.log10(5), 10)\n",
    "bins = np.logspace(np.log10(0.5),np.log10(60), 12)\n",
    "ensemble_id = 1\n",
    "clusterensemble = ClusterEnsemble(ensemble_id)\n",
    "for cluster in gclist:\n",
    "    clusterensemble.make_individual_radial_profile(\n",
    "        galaxycluster=cluster,\n",
    "        tan_component_in=\"g_t\",\n",
    "        cross_component_in=\"g_x\",\n",
    "        tan_component_out=\"g_t\",\n",
    "        cross_component_out=\"g_x\",\n",
    "        weights_in=\"w_ls\",\n",
    "        weights_out=\"W_l\",\n",
    "        bins=bins,\n",
    "        bin_units=\"arcmin\",\n",
    "#        bin_units=\"Mpc\",\n",
    "        cosmo=cosmo_clmm,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a490213d-5051-4f33-acda-2be29e928e82",
   "metadata": {},
   "source": [
    "The individual cluster data and profiles are stored at the `.data` table of the `ClusterEnsemble`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9865b58c-a428-4e54-b942-2a671c0a771a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterensemble.data[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798d4180-10c4-4e25-89a0-9c25d0b2192e",
   "metadata": {},
   "source": [
    "The edges of the radial bins, their units, and the cosmology are stored on the metadata of this table:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6666b394-f7df-4b13-8539-2da83dd5be68",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Stacked profile of the cluster ensemble\n",
    "The stacked radial profile of the ensemble is then obtained as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7daf03-ef68-4060-b385-c89f734284d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterensemble.make_stacked_radial_profile(tan_component=\"g_t\", cross_component=\"g_x\", weights=\"W_l\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f4f65a-6331-4f64-bac8-3ebe5f4d8d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterensemble.stacked_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de99242-1c98-4df0-bf23-3e04ebfc258d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Jackknife covariance of the stack between radial bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d2b8d3-6e33-4085-92d7-23c1f5c03427",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clusterensemble.compute_jackknife_covariance(\n",
    "    n_side=16, tan_component=\"g_t\", cross_component=\"g_x\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21e0a19-de24-4b3e-bbc9-527e3a58019a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Visualizing the stacked profiles\n",
    "In the figure below, we plot:\n",
    "- the individual g_t profiles of the clusters (light blue)\n",
    "- the stacked signal (red symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7f0afb-5a8a-4193-9a08-70817fd2129c",
   "metadata": {},
   "outputs": [],
   "source": [
    "moo = clmm.Modeling(massdef=\"critical\", delta_mdef=200, halo_profile_model=\"nfw\")\n",
    "moo.set_cosmo(cosmo_clmm)\n",
    "# Average values of mass and concentration of the ensemble to be used below\n",
    "# to overplot the model on the stacked profile\n",
    "moo.set_concentration(conc_list.mean())\n",
    "moo.set_mass(cluster_m.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dea61d-f0aa-4d13-8b2e-c7fc915bd3a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from clmm.redshift.distributions import desc_srd\n",
    "\n",
    "r_stack, gt_stack, gx_stack = (clusterensemble.stacked_data[c] for c in (\"radius\", \"g_t\", \"g_x\"))\n",
    "plt.rcParams[\"axes.linewidth\"] = 2\n",
    "fig, axs = plt.subplots(1, 2, figsize=(17, 6))\n",
    "\n",
    "err_gt = clusterensemble.cov[\"tan_jk\"].diagonal() ** 0.5\n",
    "err_gx = clusterensemble.cov[\"cross_jk\"].diagonal() ** 0.5\n",
    "\n",
    "axs[0].errorbar(\n",
    "    r_stack,\n",
    "    gt_stack,\n",
    "    err_gt,\n",
    "    markersize=5,\n",
    "    c=\"r\",\n",
    "    fmt=\"o\",\n",
    "    capsize=10,\n",
    "    elinewidth=1,\n",
    "    zorder=1000,\n",
    "    alpha=1,\n",
    "    label=\"Stack\",\n",
    ")\n",
    "axs[1].errorbar(\n",
    "    r_stack,\n",
    "    gx_stack,\n",
    "    err_gx,\n",
    "    markersize=5,\n",
    "    c=\"r\",\n",
    "    fmt=\"o\",\n",
    "    capsize=10,\n",
    "    elinewidth=1,\n",
    "    zorder=1000,\n",
    "    alpha=1,\n",
    "    label=\"Stack\",\n",
    ")\n",
    "\n",
    "axs[0].set_xscale(\"log\")\n",
    "axs[0].set_yscale(\"log\")\n",
    "axs[1].set_xscale(\"log\")\n",
    "\n",
    "\n",
    "for i in range(N):\n",
    "    axs[0].plot(\n",
    "        clusterensemble.data[\"radius\"][i],\n",
    "        clusterensemble.data[\"g_t\"][i],\n",
    "        color=\"cyan\",\n",
    "        label=\"Individual\",\n",
    "        alpha=1,\n",
    "        linewidth=1,\n",
    "    )\n",
    "    axs[1].plot(\n",
    "        clusterensemble.data[\"radius\"][i],\n",
    "        clusterensemble.data[\"g_x\"][i],\n",
    "        color=\"cyan\",\n",
    "        label=\"Individual\",\n",
    "        alpha=1,\n",
    "        linewidth=1,\n",
    "    )\n",
    "    if i == 0:\n",
    "        axs[0].legend(frameon=False, fontsize=15)\n",
    "        axs[1].legend(frameon=False, fontsize=15)\n",
    "# axs[0].plot(np.average(clusterensemble.data['radius'], axis = 0), np.average(clusterensemble.data['gt'], weights = None, axis = 0)/1e13)\n",
    "# axs[0].set_xlabel(\"R [Mpc]\", fontsize=20)\n",
    "# axs[1].set_xlabel(\"R [Mpc]\", fontsize=20)\n",
    "axs[0].set_xlabel(\"separation [arcmin]\", fontsize=20)\n",
    "axs[1].set_xlabel(\"separation [arcmin]\", fontsize=20)\n",
    "axs[0].tick_params(axis=\"both\", which=\"major\", labelsize=18)\n",
    "axs[1].tick_params(axis=\"both\", which=\"major\", labelsize=18)\n",
    "axs[0].set_ylabel(r\"$g_+$\", fontsize=20)\n",
    "axs[1].set_ylabel(r\"$g_\\times$\", fontsize=20)\n",
    "axs[0].set_title(r\"Tangential\", fontsize=20)\n",
    "axs[1].set_title(r\"Cross\", fontsize=20)\n",
    "\n",
    "for ax in axs:\n",
    "    ax.minorticks_on()\n",
    "    ax.grid(lw=0.5)\n",
    "    ax.grid(which=\"minor\", lw=0.1)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d31ea5f-b7c3-4281-8c97-6d6bd9ccca35",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Saving/Loading ClusterEnsemble\n",
    "The `ClusterEnsemble` object also have an option for saving/loading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515f4ea6-e759-465c-93f6-f1c5ea9130a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterensemble.save(\"ce.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d012995-d07d-4c1e-94b8-63bbc56cb457",
   "metadata": {},
   "source": [
    "## Compute reduced shear profile with TreeCorr and compare to CLMM stacked profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4ea865-74cb-42ef-b4c0-50bf8ce2bf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import treecorr\n",
    "# Source catalog\n",
    "cat_source = treecorr.Catalog(\n",
    "    ra = galcat_tot[\"ra\"],\n",
    "    dec = galcat_tot[\"dec\"],\n",
    "    g1 = galcat_tot[\"e1\"],\n",
    "    g2 = galcat_tot[\"e2\"],\n",
    "    ra_units = \"deg\",\n",
    "    dec_units = \"deg\",\n",
    "    w=galcat_tot[\"w_ls\"] \n",
    ")\n",
    "\n",
    "# Cluster catalog\n",
    "cat_cluster = treecorr.Catalog(\n",
    "    ra = clusterensemble[\"ra\"],\n",
    "    dec = clusterensemble[\"dec\"],\n",
    "    ra_units = \"deg\",\n",
    "    dec_units = \"deg\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efc3109-4327-4768-9465-d72898791d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ng = treecorr.NGCorrelation(nbins=11, min_sep=0.5, max_sep=60, sep_units=\"arcmin\",bin_type = \"Log\")#, bin_slop=0.1)\n",
    "ng.process(cat_cluster,cat_source)\n",
    "theta = ng.meanr # average angular separation in each bin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9feccc2-2178-45e7-9f1e-4bfb2d307179",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmo_clmm.be_cosmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459bba0e-213e-4b86-89f2-7068cc391a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = cosmo.angular_diameter_distance(1./(1.+np.mean(clusterensemble[\"z\"])))\n",
    "da_clmm = cosmo_clmm.eval_da(np.mean(clusterensemble[\"z\"]))\n",
    "da, da_clmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7b0ead-7733-467a-9c5c-bdf8f0278f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "arcmin_to_Mpc =  np.pi / (60. * 180) * da_clmm\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10,5))\n",
    "# ax.errorbar(R, ng.xi, np.sqrt(ng.varxi), color='blue', marker='o', \n",
    "#                  linestyle='', label='Treecorr - clusters positions x source shear')\n",
    "ax.errorbar(theta, ng.xi, np.sqrt(ng.varxi), color='blue', marker='x', markersize=15,\n",
    "                  linestyle='', label='Treecorr - cluster positions x source shears')\n",
    "\n",
    "\n",
    "# axes[0].errorbar(1.1*R_highm_ran*cosmo.H0/100., ng_highm_ran.xi, np.sqrt(ng_highm_ran.varxi), color = 'grey', marker='o',\n",
    "#                  linestyle='', label='shuffle RA ~ random cluster locations')\n",
    "ax.errorbar(\n",
    "    r_stack,\n",
    "    gt_stack,\n",
    "    err_gt,\n",
    "    markersize=5,\n",
    "    c=\"r\",\n",
    "    fmt=\".\",\n",
    "    capsize=10,\n",
    "    elinewidth=1,\n",
    "    zorder=1000,\n",
    "    alpha=1,\n",
    "    label=\"CLMM - stacked reduced rangential shear\",\n",
    ")\n",
    "\n",
    "ax.plot(\n",
    "    clusterensemble.data[\"radius\"][0],\n",
    "    moo.eval_reduced_tangential_shear(clusterensemble.data[\"radius\"][0]*arcmin_to_Mpc, cluster_z.mean(), \n",
    "                                    z_src=desc_srd, z_src_info='distribution'),\n",
    "    \"--k\",\n",
    "    linewidth=1,\n",
    "    label=\"CLMM prediction for stack 'mean' cluster\",\n",
    "    zorder=100,\n",
    ")\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylim([-0.02,0.15])\n",
    "ax.axhline(0, color='k', ls=':')\n",
    "ax.set_xlabel('separation [arcmin]')\n",
    "ax.set_ylabel('$\\widehat{g_t}$')\n",
    "ax.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992a44f3-0f57-44fd-bd78-62326016631c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(err_gt, np.sqrt(ng.varxi))\n",
    "plt.plot([0, 0.007],[0, 0.007], 'k:')\n",
    "plt.xlabel(\"Error from CLMM\")\n",
    "plt.ylabel(\"Error from TreeCorr\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Txpipe_clp",
   "language": "python",
   "name": "txpipe_clp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
