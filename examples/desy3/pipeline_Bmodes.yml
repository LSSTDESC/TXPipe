
# Stages to run
stages:
    #- name: TXBrighterFatterPlot # Make plots tracking the brighter-fatter effect
    - name: TXPSFDiagnostics     # Compute and plots other PSF diagnostics
    #- name: TXRoweStatistics     # Compute and plot Rowe statistics
    #  threads_per_process: 2
    - name: TXAuxiliaryLensMaps    # make depth and bright object maps
    - name: TXSimpleMask         # combine maps to make a simple mask
    - name: TXSourceSelectorMetacal  # select and split objects into source bins
    - name: TXSourceNoiseMaps    # Compute shear noise using rotations
    - name: TXShearCalibration     # Calibrate and split the source sample tomographically
    - name: TXSourceMaps           # make source g1 and g2 maps
    - name: TXConvergenceMaps    # Make convergence kappa maps from g1, g2 maps
    - name: TXAuxiliarySourceMaps  # make PSF and flag maps
    - name: FlowCreator             # Simulate a spectroscopic population
    - name: GridSelection          # Simulate a spectroscopic sample
    - name: TXParqetToHDF          # Convert the spec sample format
    - name: PZPrepareEstimatorLens   # Prepare the p(z) estimator
      classname: Inform_BPZ_lite   
    - name: PZEstimatorLens        # Measure lens galaxy PDFs
      classname: BPZ_lite
    - name: TXMeanLensSelector     # select objects for lens bins from the PDFs
    - name: Inform_NZDirLens       # Prepare the DIR method inputs for the lens sample     
      classname: Inform_NZDir
    - name: Inform_NZDirSource     # Prepare the DIR method inputs for the source sample
      classname: Inform_NZDir
    - name: PZRailSummarizeLens    # Run the DIR method on the lens sample to find n(z)
      classname: PZRailSummarize  
    - name: PZRailSummarizeSource  # Run the DIR method on the lens sample to find n(z)
      classname: PZRailSummarize
    - name: TXLensCatalogSplitter  # Split the lens sample tomographically
    - name: TXLSSWeightsUnit     # add systematic weights to the lens sample (weight=1 for this example)
    #- name: TXStarCatalogSplitter  # Split the star catalog into separate bins (psf/non-psf)
    #- name: TXSourceMaps           # make source g1 and g2 maps
    #- name: TXLensMaps             # make source lens and n_gal maps
    #- name: TXAuxiliarySourceMaps  # make PSF and flag maps
    #- name: TXAuxiliaryLensMaps    # make depth and bright object maps
    #- name: TXSimpleMask         # combine maps to make a simple mask
    #- name: TXLSSWeightsUnit     # add systematic weights to the lens sample (weight=1 for this example)
    #- name: TXSourceNoiseMaps    # Compute shear noise using rotations
    #- name: TXLensNoiseMaps      # Compute lens noise using half-splits
    #- name: TXDensityMaps        # turn mask and ngal maps into overdensity maps
    #- name: TXMapPlots           # make pictures of all the maps
    #- name: TXTracerMetadata     # collate metadata
    #- name: TXRandomCat          # generate lens bin random catalogs
    #- name: TXJackknifeCenters   # Split the area into jackknife regions
    #- name: TXTwoPoint           # Compute real-space 2-point correlations
    #  threads_per_process: 2
    #- name: TXBlinding           # Blind the data following Muir et al
    #  threads_per_process: 2
    #- name: TXTwoPointTheoryReal # compute theory using CCL to save in sacc file and plot later
    #- name: TXTwoPointPlotsTheory      # Make plots of 2pt correlations
    #- name: TXSourceDiagnosticPlots    # Make a suite of diagnostic plots
    #- name: TXLensDiagnosticPlots    # Make a suite of diagnostic plots
    #- name: TXGammaTFieldCenters # Compute and plot gamma_t around center points
    #  threads_per_process: 2
    #- name: TXGammaTStars  # Compute and plot gamma_t around bright stars
    #  threads_per_process: 2
    #- name: TXGammaTRandoms      # Compute and plot gamma_t around randoms
    #  threads_per_process: 2
    #- name: TXGalaxyStarDensity  # Compute and plot the star-galaxy density cross-correlation
    #- name: TXGalaxyStarShear    # Compute and plot the star-galaxy shear cross-correlation
    #- name: TXPhotozPlotSource        # Plot the bin n(z)
    #  classname: TXPhotozPlot
    #- name: TXPhotozPlotLens        # Plot the bin n(z)
    #  classname: TXPhotozPlot
    #- name: TXConvergenceMaps    # Make convergence kappa maps from g1, g2 maps
    #- name: TXConvergenceMapPlots # Plot the convergence map
    #- name: TXMapCorrelations    # plot the correlations between systematics and data
    #- name: TXApertureMass        # Compute aperture-mass statistics
    #  threads_per_process: 2
    #- name: TXTwoPointFourier    # Compute power spectra C_ell
    # Disablig this since not yet synchronised with new Treecorr MPI
    # - name: TXSelfCalibrationIA   # Self-calibration intrinsic alignments of galaxies
    # Disabling these as they take too long for a quick test.
    # - name: TXRealGaussianCovariance   # Compute covariance of real-space correlations
    # - name: TXTwoPointFourier          # Compute power spectra C_ell
    # - name: TXFourierNamasterCovariance # Compute the C_ell covariance
    # - name: TXFourierTJPCovariance     # Compute the C_ell covariance with TJPCov 


# modules and packages to import that have pipeline
# stages defined in them
modules: >
    txpipe
    rail.creation.degradation.grid_selection
    rail.creation.engines.flowEngine
    rail.estimation.algos.NZDir
    rail.estimation.algos.bpz_lite

# where to find any modules that are not in this repo,
# and any other code we need.
python_paths:
    - submodules/WLMassMap/python/desc/

# Where to put outputs
output_dir: data/desy3a/outputs

# How to run the pipeline: mini, parsl, or cwl
launcher:
    name: mini
    interval: 1.0

# Where to run the pipeline: cori-interactive, cori-batch, or local
site:
    name: local
    max_threads: 2

# configuration settings
config: examples/desy3/config_Bmodes.yml

# These are overall inputs to the whole pipeline, not generated within it
inputs:
    # See README for paths to download these files
    #shear_catalog: data/example/inputs/shear_catalog.hdf5
    shear_catalog: //global/cfs/cdirs/lsst/groups/WL/projects/txpipe-sys-tests/des-y3/shear_catalog_desy3_unmasked_withfakez_v2.h5
    photometry_catalog: data/example/inputs/photometry_catalog.hdf5
    calibration_table: data/example/inputs/sample_cosmodc2_w10year_errors.dat
    exposures: data/example/inputs/exposures.hdf5
    #star_catalog: data/example/inputs/star_catalog.hdf5
    star_catalog: /global/cfs/cdirs/lsst/groups/WL/projects/txpipe-sys-tests/des-y3/DES_psf_y3_catalog.hdf5
    #lens_tomography_catalog: /global/cfs/cdirs/lsst/groups/WL/users/yomori/repo/aaa/TXPipe/data/desy3a/outputs/lens_tomography_catalog_unweighted.hdf5 ##############<----- manually add this line
    # This file comes with the code
    fiducial_cosmology: data/fiducial_cosmology.yml
    # For the self-calibration extension we are not using Random_cat_source for now
    # So it is set to Null, so the yaml intepreter returns a None value to python. 
    random_cats_source: Null
    flow: data/example/inputs/example_flow.pkl

# These are overall inputs to the whole pipeline, not generated within it
#inputs:
#    shear_catalog: //global/cfs/cdirs/lsst/groups/WL/projects/txpipe-sys-tests/des-y3/shear_catalog_desy3_unmasked_withfakez_v2.h5
#    photometry_catalog: 
#    #shear_tomography_catalog: /global/cfs/cdirs/desc-wl/projects/txpipe-sys-tests/des-y3/shear_tomography_desy3_unmasked_test.h5
#    lens_tomography_catalog: /global/cfs/cdirs/lsst/groups/WL/projects/txpipe-sys-tests/des-y1/lens_tomography_catalog_desy1_RM.h5
#    lens_photoz_stack: 
#    mask: /global/cfs/cdirs/lsst/groups/WL/projects/txpipe-sys-tests/des-y1/mask_desy1.h5
#    star_catalog: /global/cfs/cdirs/lsst/groups/WL/projects/txpipe-sys-tests/des-y3/DES_psf_y3_catalog.h5
#    calibration_table: data/example/inputs/sample_cosmodc2_w10year_errors.dat
#    fiducial_cosmology: data/fiducial_cosmology.yml
#    random_cats_source: Null
#    flow: data/example/inputs/example_flow.pkl


# if supported by the launcher, restart the pipeline where it left off
# if interrupted
resume: True
# where to put output logs for individual stages
log_dir: data/desy3a/logs
# where to put an overall parsl pipeline log
pipeline_log: data/desy3a/log.txt
