
# Stages to run
stages:
    - name: TXSourceSelector
    - name: TXTruthLensSelector
    - name: FlexZPipe
      #- name: PZPDFMLZ
    - name: TXPhotozStack
    - name: TXDiagnosticMaps
    - name: TXRandomCat
    - name: TXJackknifeCenters
    - name: TXTwoPoint
      threads_per_process: 2
    - name: TXBlinding
      threads_per_process: 2
    - name: TXTwoPointPlots
    - name: TXDiagnosticPlots
    - name: TXGammaTFieldCenters
      threads_per_process: 2
    - name: TXGammaTBrightStars
      threads_per_process: 2
    - name: TXGammaTDimStars
      threads_per_process: 2
    - name: TXRoweStatistics
      threads_per_process: 2
    - name: TXPSFDiagnostics
    - name: TXRealGaussianCovariance
      threads_per_process: 2
    - name: TXNoiseMaps
      threads_per_process: 2
    - name: TXTwoPointFourier
      threads_per_process: 2
    - name: TXFourierGaussianCovariance
      threads_per_process: 2

# Where to put outputs
output_dir: data/example/outputs

# How to run the pipeline: mini, parsl, or cwl
launcher:
    name: mini
    interval: 1.0

# Where to run the pipeline: cori-interactive, cori-batch, or local
site:
    name: local
    max_threads: 1

# python modules to import to search for stages
modules: txpipe

# configuration settings
config: examples/config/laptop_config.yml

# On NERSC, set this before running:
# export DATA=${LSST}/groups/WL/users/zuntz/data/metacal-testbed

inputs:
    # See README for paths to download these files
    shear_catalog: data/example/inputs/shear_catalog.hdf5
    photometry_catalog: data/example/inputs/photometry_catalog.hdf5
    photoz_trained_model: data/example/inputs/cosmoDC2_trees_i25.3.npy
    calibration_table: data/example/inputs/sample_cosmodc2_w10year_errors.dat
    exposures: data/example/inputs/exposures.hdf5
    star_catalog: data/example/inputs/star_catalog.hdf5
    # This file comes with the code
    fiducial_cosmology: data/fiducial_cosmology.yml

# if supported by the launcher, restart the pipeline where it left off
# if interrupted
resume: True
# where to put output logs for individual stages
log_dir: data/example/logs
# where to put an overall parsl pipeline log
pipeline_log: data/example/log.txt

